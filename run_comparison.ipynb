{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cef380b5-21c7-4d35-a169-90ccb2813192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in ./.local/lib/python3.8/site-packages (0.19.0)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.39.0-py3-none-any.whl (92.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 92.2 MB 389 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from accelerate) (1.10.1+cu111)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.6.0->accelerate) (4.6.3)\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.39.0\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate bitsandbytes datasets einops tfds-nightly tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79c48e61-ae32-4ca8-818b-4c9cadc12fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/qblocks/.local/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda111.so\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.9\n",
      "CUDA SETUP: Detected CUDA version 111\n",
      "CUDA SETUP: Loading binary /home/qblocks/.local/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda111.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qblocks/.local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib'), PosixPath('/usr/local/nvidia/lib64')}\n",
      "  warn(msg)\n",
      "/home/qblocks/.local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/local/nvidia/lib:/usr/local/nvidia/lib64 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/home/qblocks/.local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(msg)\n",
      "/home/qblocks/.local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:43<00:00, 21.70s/it]\n"
     ]
    }
   ],
   "source": [
    "from jsonformer import Jsonformer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tiiuae/falcon-7b-instruct\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"tiiuae/falcon-7b-instruct\",  trust_remote_code=True,load_in_8bit=True,\n",
    "        device_map='auto',\n",
    "        torch_dtype=torch.float16,\n",
    "        low_cpu_mem_usage=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "67a05838-0017-4fa1-a34f-be65c77d4c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = pd.read_csv(\"created_data_wikilingua.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "25a506e2-47bb-47eb-9bb1-9a522cb4eb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "\n",
    "import re\n",
    "\n",
    "def decode_byte_string(input_string):\n",
    "    # find the byte string using regex\n",
    "    byte_string_match = re.search(r\"b'([^']*)'|b\\\"([^\\\"]*)\\\"\", input_string)\n",
    "    \n",
    "    if byte_string_match is None:\n",
    "        return input_string\n",
    "\n",
    "    byte_string = byte_string_match.group(0)\n",
    "    \n",
    "    # replace escaped quotes with unescaped ones\n",
    "    byte_string = byte_string.replace('\\\\\\'', '\\'')\n",
    "    byte_string = byte_string.replace('\\\\\\\"', '\\\"')\n",
    "    \n",
    "    # safely parse the byte string as a Python literal and decode it\n",
    "    try:\n",
    "        decoded = ast.literal_eval(byte_string).decode('utf-8')\n",
    "    except (ValueError, SyntaxError):\n",
    "        return input_string\n",
    "\n",
    "    # replace the byte string in the input string with the decoded string\n",
    "    output_string = input_string.replace(byte_string_match.group(0), decoded)\n",
    "\n",
    "    return output_string\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c1f902df-1423-4c7f-87e9-3fd6590c4633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.2333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1595/784421871.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_human.replace({'Yes': 1, 'No': 0,'Unsure':0}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "class CompareHumantoModel:\n",
    "    def __init__(self, model, tokenizer, data_for_model):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data_for_model = data_for_model\n",
    "        self.json_schema = {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\":{\n",
    "                \"question1\":{\"type\": \"string\"},\n",
    "                \"question2\":{\"type\": \"string\"},\n",
    "                \"question3\":{\"type\": \"string\"},\n",
    "                \"question4\":{\"type\": \"string\"},\n",
    "                \"question5\":{\"type\": \"string\"},\n",
    "                \"question6\":{\"type\": \"string\"},\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def generate_answers(self):\n",
    "        results = []\n",
    "\n",
    "        for idx, data in self.data_for_model.iterrows():\n",
    "            summary = data['summary']\n",
    "            article = data['source']\n",
    "            prompt = self._create_prompt(article, summary)\n",
    "            jsonformer = Jsonformer(self.model, self.tokenizer, self.json_schema, prompt)\n",
    "            generated_data = jsonformer()\n",
    "            results.append(generated_data)\n",
    "\n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_prompt(article, summary):\n",
    "        return f\"\"\"article:{article}\n",
    "        summary:{summary}\n",
    "\n",
    "        return answer for questions- \n",
    "\n",
    "        Q1 comprehensible: The summary can be read\n",
    "        and understood by the rater. (If “No,” the rest\n",
    "        of the questions will be skipped.)\n",
    "        Q2 repetition: The summary is free of unnecessarily repeated information.\n",
    "        Q3 grammar: The summary is grammatically\n",
    "        correct.\n",
    "        Q4 attribution: All of the information provided\n",
    "        by the summary is fully attributable to the\n",
    "        source article, as defined in (Rashkin et al.,\n",
    "        2021).\n",
    "        Q5 main ideas: The summary captures the main\n",
    "        idea(s) of the source article.\n",
    "        Q6 conciseness: The summary concisely represents the information in the source article.\n",
    "\n",
    "        All answers are only Yes/No in the following schema:\"\"\"\n",
    "\n",
    "class MeanSquaredErrorCalculator:\n",
    "    @staticmethod\n",
    "    def calculate_mse(df_generated, df_human):\n",
    "        df_generated.replace({'Yes': 1, 'No': 0}, inplace=True)\n",
    "        df_human.replace({'Yes': 1, 'No': 0,'Unsure':0}, inplace=True)\n",
    "        df_human = df_human.reset_index().drop('index',axis=1)\n",
    "\n",
    "        mse_row_wise = []\n",
    "        for idx in range(0, len(df_generated)):\n",
    "            mse_row_wise.append(mean_squared_error(df_generated.iloc[idx].values.flatten(),df_human.iloc[idx].values.flatten()))\n",
    "        \n",
    "        return np.mean(mse_row_wise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f4a99374-d3d9-4c35-8d44-41961522186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X['source'] = X['source'].apply(lambda x:decode_byte_string(x))\n",
    "X[X.model=='t5_xxl']\n",
    "data_for_model = X[X.model=='mt5_xxl'][:10]\n",
    "\n",
    "question_answer_generator = CompareHumantoModel(model, tokenizer, data_for_model)\n",
    "df_generated = question_answer_generator.generate_answers()\n",
    "\n",
    "df_human_score = data_for_model[['question1', 'question2', 'question3', 'question4', 'question5','question6']]\n",
    "mse_calculator = MeanSquaredErrorCalculator()\n",
    "mse = mse_calculator.calculate_mse(df_generated, df_human_score)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
